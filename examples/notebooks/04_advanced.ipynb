{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GliaGL Advanced Techniques\n",
    "\n",
    "Advanced patterns for custom workflows and optimization.\n",
    "\n",
    "## What You'll Learn\n",
    "- Custom training loops\n",
    "- Advanced NumPy integration\n",
    "- Sparse matrix operations\n",
    "- Performance optimization\n",
    "- Custom architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glia\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "\n",
    "print(f\"GliaGL version: {glia.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom Training Loop with Early Stopping\n",
    "\n",
    "Implement a custom training loop with patience-based early stopping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_early_stopping(net, train_data, val_data, config, patience=10):\n",
    "    \"\"\"Train with early stopping\"\"\"\n",
    "    trainer = glia.Trainer(net, config)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    history = {'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(100):  # Max 100 epochs\n",
    "        # Train one epoch\n",
    "        trainer.train_epoch(train_data, epochs=1, config=config)\n",
    "        train_acc = trainer.epoch_accuracy[-1]\n",
    "        \n",
    "        # Validate\n",
    "        correct = sum(1 for ep in val_data \n",
    "                      if trainer.evaluate(ep.seq, config).winner_id == ep.target_id)\n",
    "        val_acc = correct / len(val_data)\n",
    "        \n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            net.save('best_checkpoint.net')\n",
    "            print(f\"Epoch {epoch}: val_acc={val_acc:.3f} (new best!)\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    return history, best_acc\n",
    "\n",
    "# Test it\n",
    "net = glia.Network(num_sensory=2, num_neurons=4)\n",
    "net.set_weights(['S0', 'S1'], ['N2', 'N3'], np.array([1.5, 1.5]))\n",
    "\n",
    "# Create simple dataset\n",
    "episodes = []\n",
    "for i in range(20):\n",
    "    ep = glia.EpisodeData()\n",
    "    seq = glia.InputSequence()\n",
    "    seq.add_timestep({'S0': 100.0 if i % 2 == 0 else 0.0, 'S1': 0.0})\n",
    "    ep.seq = seq\n",
    "    ep.target_id = 'N2' if i % 2 == 0 else 'N3'\n",
    "    episodes.append(ep)\n",
    "\n",
    "dataset = glia.Dataset(episodes)\n",
    "train, val = dataset.split(0.8, seed=42)\n",
    "config = glia.create_config(lr=0.01, batch_size=4)\n",
    "\n",
    "history, best_acc = train_with_early_stopping(net, train, val, config, patience=5)\n",
    "print(f\"\\nBest validation accuracy: {best_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sparse Matrix Operations\n",
    "\n",
    "Convert network to sparse adjacency matrix for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_to_sparse_matrix(net):\n",
    "    \"\"\"Convert network to sparse adjacency matrix\"\"\"\n",
    "    from_ids, to_ids, weights = net.get_weights()\n",
    "    \n",
    "    # Create ID to index mapping\n",
    "    all_ids = net.neuron_ids\n",
    "    id_to_idx = {nid: i for i, nid in enumerate(all_ids)}\n",
    "    \n",
    "    # Convert to indices\n",
    "    row = [id_to_idx[fid] for fid in from_ids]\n",
    "    col = [id_to_idx[tid] for tid in to_ids]\n",
    "    \n",
    "    # Create sparse matrix\n",
    "    n = len(all_ids)\n",
    "    adj_matrix = coo_matrix((weights, (row, col)), shape=(n, n))\n",
    "    \n",
    "    return adj_matrix, all_ids\n",
    "\n",
    "# Analyze network connectivity\n",
    "adj_matrix, ids = network_to_sparse_matrix(net)\n",
    "adj_csr = adj_matrix.tocsr()\n",
    "\n",
    "# Compute in-degree and out-degree\n",
    "in_degree = np.array(adj_csr.sum(axis=0)).flatten()\n",
    "out_degree = np.array(adj_csr.sum(axis=1)).flatten()\n",
    "\n",
    "print(\"Network connectivity analysis:\")\n",
    "for nid, in_deg, out_deg in zip(ids, in_degree, out_degree):\n",
    "    print(f\"  {nid}: in={in_deg:.1f}, out={out_deg:.1f}\")\n",
    "\n",
    "# Sparsity\n",
    "sparsity = 1 - (len(adj_matrix.data) / (len(ids) ** 2))\n",
    "print(f\"\\nSparsity: {sparsity:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch State Collection (Memory Efficient)\n",
    "\n",
    "Efficiently collect state over many timesteps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_state_history(net, n_timesteps, input_fn=None):\n",
    "    \"\"\"Efficiently collect state over time\"\"\"\n",
    "    # Pre-allocate arrays\n",
    "    ids, values, thresholds, leaks = net.get_state()\n",
    "    n_neurons = len(ids)\n",
    "    \n",
    "    value_history = np.zeros((n_timesteps, n_neurons))\n",
    "    firing_history = []\n",
    "    \n",
    "    # Collect without repeated allocations\n",
    "    for t in range(n_timesteps):\n",
    "        # Optional input\n",
    "        if input_fn:\n",
    "            inputs = input_fn(t)\n",
    "            if inputs:\n",
    "                net.inject_dict(inputs)\n",
    "        \n",
    "        # Step\n",
    "        net.step()\n",
    "        \n",
    "        # Collect state (zero-copy)\n",
    "        _, values, _, _ = net.get_state()\n",
    "        value_history[t] = values\n",
    "        \n",
    "        # Track firing\n",
    "        fired = net.get_firing_neurons()\n",
    "        if fired:\n",
    "            firing_history.append((t, fired))\n",
    "    \n",
    "    return value_history, firing_history, ids\n",
    "\n",
    "# Test it with periodic input\n",
    "net.reset()\n",
    "\n",
    "def periodic_input(t):\n",
    "    if t % 20 == 0:\n",
    "        return {'S0': 100.0, 'S1': 50.0}\n",
    "    return None\n",
    "\n",
    "values, firings, ids = collect_state_history(net, 100, periodic_input)\n",
    "\n",
    "print(f\"Collected {len(values)} timesteps\")\n",
    "print(f\"Firing events: {len(firings)}\")\n",
    "\n",
    "# Plot membrane voltage over time\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i, nid in enumerate(ids):\n",
    "    plt.plot(values[:, i], label=nid, alpha=0.7)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Membrane Voltage')\n",
    "plt.title('Neuron Activity Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorized Parameter Updates\n",
    "\n",
    "Apply transformations to all weights at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_weight_regularization(net, l1_lambda=0.01, l2_lambda=0.001):\n",
    "    \"\"\"Apply L1 and L2 regularization to weights\"\"\"\n",
    "    from_ids, to_ids, weights = net.get_weights()\n",
    "    \n",
    "    # L1: Soft thresholding\n",
    "    weights = np.sign(weights) * np.maximum(0, np.abs(weights) - l1_lambda)\n",
    "    \n",
    "    # L2: Scaling\n",
    "    weights *= (1 - l2_lambda)\n",
    "    \n",
    "    # Remove near-zero weights\n",
    "    mask = np.abs(weights) > 1e-6\n",
    "    net.set_weights(\n",
    "        [f for f, m in zip(from_ids, mask) if m],\n",
    "        [t for t, m in zip(to_ids, mask) if m],\n",
    "        weights[mask]\n",
    "    )\n",
    "    \n",
    "    return net\n",
    "\n",
    "# Test regularization\n",
    "print(f\"Before regularization: {net.num_connections} connections\")\n",
    "apply_weight_regularization(net, l1_lambda=0.1, l2_lambda=0.01)\n",
    "print(f\"After regularization: {net.num_connections} connections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Custom Network Architecture\n",
    "\n",
    "Build a layered feedforward network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layered_network(n_input, n_hidden, n_output, density=0.5):\n",
    "    \"\"\"Create a feedforward layered network\"\"\"\n",
    "    net = glia.Network(num_sensory=n_input, num_neurons=n_hidden + n_output)\n",
    "    \n",
    "    from_ids = []\n",
    "    to_ids = []\n",
    "    weights = []\n",
    "    \n",
    "    # Input → Hidden connections\n",
    "    for i in range(n_input):\n",
    "        for h in range(n_hidden):\n",
    "            if np.random.rand() < density:\n",
    "                from_ids.append(f'S{i}')\n",
    "                to_ids.append(f'N{h}')\n",
    "                weights.append(np.random.randn() * 0.5)\n",
    "    \n",
    "    # Hidden → Output connections\n",
    "    for h in range(n_hidden):\n",
    "        for o in range(n_output):\n",
    "            if np.random.rand() < density:\n",
    "                from_ids.append(f'N{h}')\n",
    "                to_ids.append(f'N{n_hidden + o}')\n",
    "                weights.append(np.random.randn() * 0.5)\n",
    "    \n",
    "    net.set_weights(from_ids, to_ids, np.array(weights))\n",
    "    return net\n",
    "\n",
    "# Create layered network\n",
    "layered_net = create_layered_network(n_input=3, n_hidden=6, n_output=3, density=0.6)\n",
    "print(f\"Layered network: {layered_net.num_neurons} neurons, {layered_net.num_connections} connections\")\n",
    "\n",
    "# Visualize if possible\n",
    "try:\n",
    "    import glia.viz as viz\n",
    "    viz.plot_network(layered_net, show=True)\n",
    "    plt.title(\"Layered Network Architecture\")\n",
    "    plt.show()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Profiling\n",
    "\n",
    "Measure performance of different operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def profile_operations(net, n_iterations=1000):\n",
    "    \"\"\"Profile network operations\"\"\"\n",
    "    timings = {}\n",
    "    \n",
    "    # Step\n",
    "    start = time.time()\n",
    "    for _ in range(n_iterations):\n",
    "        net.step()\n",
    "    timings['step'] = (time.time() - start) / n_iterations\n",
    "    \n",
    "    # Get state\n",
    "    start = time.time()\n",
    "    for _ in range(n_iterations):\n",
    "        net.get_state()\n",
    "    timings['get_state'] = (time.time() - start) / n_iterations\n",
    "    \n",
    "    # Get weights\n",
    "    start = time.time()\n",
    "    for _ in range(n_iterations):\n",
    "        net.get_weights()\n",
    "    timings['get_weights'] = (time.time() - start) / n_iterations\n",
    "    \n",
    "    return timings\n",
    "\n",
    "# Profile\n",
    "timings = profile_operations(net, n_iterations=1000)\n",
    "\n",
    "print(\"Performance (per operation):\")\n",
    "for op, t in timings.items():\n",
    "    print(f\"  {op}: {t*1000:.3f} ms ({1/t:.0f} ops/sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "- ✅ Custom training loops with early stopping\n",
    "- ✅ Sparse matrix operations for analysis\n",
    "- ✅ Memory-efficient state collection\n",
    "- ✅ Vectorized parameter updates\n",
    "- ✅ Custom network architectures\n",
    "- ✅ Performance profiling\n",
    "\n",
    "## Key Techniques\n",
    "\n",
    "- **Zero-copy NumPy**: Direct array access for performance\n",
    "- **Sparse matrices**: Efficient large network representation\n",
    "- **Vectorized ops**: Apply transformations to all parameters\n",
    "- **Custom loops**: Full control over training process\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Full API**: See `docs/user-guide/API_REFERENCE.md`\n",
    "- **Advanced Guide**: See `docs/user-guide/ADVANCED_USAGE.md`\n",
    "- **NumPy Details**: See `docs/development/numpy_interface.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
